---
title: "Probabilistic Reconciliation via Conditioning with `bayesRecon`"
author: "Nicolò Rubattu, Giorgio Corani, Dario Azzimonti, Lorenzo Zambon"
date: "2023-06-28"
lang: "en"
output: html_vignette
bibliography: references.bib
cite:
- '@zambon2022probabilistic'
- '@zambon2023properties'
- '@corani2023probabilistic'
- '@corani2021probabilistic'
- '@athanasopoulos2017forecasting'
- '@wickramasuriya2019optimal'
vignette: >
  %\VignetteIndexEntry{Probabilistic Reconciliation via Conditioning with `bayesRecon`}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval=TRUE ### !!!! set to FALSE here to render only the text !!!!
)
set.seed(42)
```

```{r klippy, echo=FALSE, include=TRUE, eval=FALSE}
klippy::klippy(position = c('top', 'right'), tooltip_message = 'Copy', tooltip_success = 'Done', color="black")
```

# Introduction

This vignette demostrates how to use the `bayesRecon` package to *reconcile hierarchical probabilistic forecasts*.

The **Carpart** example uses temporal hierarchy and the Bottom-Up Importance Sampling (BUIS) reconciliation algorithm for count time series.

The **M3** example uses temporal hierarchy and Gaussian reconciliation.

The **Infants mortality** example reconciles cross-sectional forecasts.

For the theory behind the implemented reconciliation algorithms, we encorage readers to refer to the following papers:

* Zambon, L., Azzimonti, D., & Corani, G. (2022). Probabilistic reconciliation of forecasts via importance sampling.

* Zambon, L., Agosto, A., Giudici, P., & Corani, G. (2023). Properties of the reconciled distributions for Gaussian and count forecasts.

* Corani, G., Azzimonti, D., & Rubattu, N. (2023). Probabilistic reconciliation of count time series.

* Corani, G., Azzimonti, D., Augusto, J. P., & Zaffalon, M. (2021). Probabilistic reconciliation of hierarchical forecast via Bayes’ rule.

Also: 

* Athanasopoulos, G., Hyndman, R. J., Kourentzes, N., & Petropoulos, F. (2017). Forecasting with temporal hierarchies.

* Wickramasuriya, S. L., Athanasopoulos, G., & Hyndman, R. J. (2019). Optimal forecast reconciliation for hierarchical and grouped time series through trace minimization.

# Setup

You can install the stable version of `bayesRecon` on [R CRAN](https://cran.r-project.org/package=bayesRecon).

```{r install, eval=FALSE}
install.packages('bayesRecon', dependencies = TRUE)
```

Load the package.
```{r load}
library(bayesRecon)
```

# Example 1: Carpart
In this example, we consider a *monthly* time series of car part sales, from Jan. 1998 to Mar. 2002. \
Precisely, it is the #2655 time series of the *carparts* dataset [@hyndman2008forecasting].

The time series consists of **count** data, and the values distribution is peaked at low values. Hence, we will use count type forecasts.

```{r carpart-plot, dpi=300, out.width = "100%", fig.align='center', fig.cap="**Figure 1**: Carpart: monthly car part sales.", fig.dim = c(6, 3)}
layout(mat = matrix(c(1, 2), nrow = 1, ncol = 2), widths = c(2, 1))
plot(carpart, xlab = "Time", ylab = "Car part sales", main = NULL)
hist(carpart, xlab = "Car part sales", main = NULL)
```
<br><br>
We use a simple train-test split, and we want to forecast the last 12 observations (i.e. 1 year ahead).
```{r train-test}
train <- window(carpart, end = c(2001, 3))
test <- window(carpart, start = c(2001, 4))
```

In order to do hierarchical forecasting:

1.    we build a temporal hierarchy;
2.    we obtain the predictions (*base forecasts*) at each temporal scale.

We build the hierarchy using the `temporal aggregation` function. We aggregate at *2-Monthly*, *Quarterly*, *4-Monthly*, *Biannual*, *Annual* by specifying the `agg_levels` argument.

``` {r temp-agg}
train.agg <- bayesRecon::temporal_aggregation(train, agg_levels = c(2, 3, 4, 6, 12))
levels <- c("Annual", "Biannual", "4-Monthly", "Quarterly", "2-Monthly", "Monthly")
names(train.agg) <- levels
```

The function returns a list of aggregated time series, ordered from the most aggregated to the bottom level.
``` {r temp-agg-plot, dpi=300, fig.show="hold", out.width="100%", out.heigth="100%", fig.align='center', fig.cap="**Figure 2**: Carpart: visualization of the aggregate time series.", fig.dim=c(6,3.5)}
par(mfrow = c(2, 3), mai = c(0.6, 0.6, 0.5, 0.5))
for (l in levels) {
  plot(train.agg[[l]], xlab = "Time", ylab = "Car part sales", main = l)
}
```
<br><br>
Since our package only implements reconciliation methods, we use a Generalized Linear Autoregressive Moving Average Model for discrete data with Poisson distribution from the package `glarma` ([R CRAN](https://cran.r-project.org/package=glarma)) to generate the predictive distributions.

The models produce forecasts for 1 year ahead, *h* steps ahead according to the temporal level.
For instance, *h=12* for the monthly level, and *h=4* for the quarterly level. 
Forecasts are in the form of samples. Each forecast is constituted by $\mathbf{B}$ samples.

In the code below a for loop is used to iterating over the temporal aggregation levels.
For each of this, an independent model is fitted. We set $\mathbf{B}=20000$.
Future samples are obtained via simulation, see the documentation of `glarma::forecast.glarma` for details.
We collect the samples in a list of length equal to the number of predictive distributions, $28$ in this example (one for *Annual*, two for *Biannual*, etc.).

``` {r hier-fore}
# install.packages("glarma", dependencies = TRUE)
library(glarma)

fc.samples <- list()
B <- 20000
fc.count <- 1
# iterating over the temporal aggregation levels [~ 30 seconds]
for (l in seq_along(train.agg)) {
  f.level <- frequency(train.agg[[l]])
  print(paste("Forecasting at ", levels[l], "...", sep = ""))
  # fit an independent model for each aggregation level
  model <- glarma::glarma(
    train.agg[[l]],
    phiLags = if (f.level == 1) 1 else 1:(min(6, f.level - 1)),
    thetaLags = if (f.level == 1) NULL else f.level,
    X = cbind(intercept = rep(1, length(train.agg[[l]]))),
    offset = cbind(intercept = rep(0, length(train.agg[[l]]))),
    type = "Poi"
  )
  # forecast 1 year ahead
  h <- f.level
  tmp <- matrix(data = NA, nrow = h, ncol = B)
  for (s in (1:B)) {
    # each call to 'forecast.glarma' returns a simulation path
    tmp[, s] <- forecast(
      model,
      n.ahead = h,
      newdata = cbind(intercept = rep(1, h)),
      newoffset = rep(0, h)
    )$Y
  }
  # collect the forecasted samples
  for (i in 1:h) {
    fc.samples[[fc.count]] <- tmp[i, ]
    fc.count <- fc.count + 1
  }
}

```

It is now the reconciliation turn, to ensure *coherent* forecasts.

We obtain the summing matrix $\mathbf{S}$ using the function `get_reconc_matrices`. It requires the aggregation factors (the same that were used before to build the hierarchy), and the forecasting horizon for the bottom time series (*h=12* in this example).

``` {r S}
recon.matrices <- bayesRecon::get_reconc_matrices(agg_levels = c(2, 3, 4, 6, 12), h = 12)
S <- recon.matrices$S # Summing matrix
A <- recon.matrices$A # A matrix
```

We use the function `reconc_BUIS` which implements the Bottom-Up Important Sampling (BUIS) algorithm.
It requires the $\mathbf{S}$ matrix, the *base forecasts*, the specification of the input type of the base forecasts ("samples" in this example), and the specification of the base forecasts distributions ("discrete" in this example, since the predictive distributions are Poisson).

``` {r reconc}
recon.res <- bayesRecon::reconc_BUIS(
  S,
  base_forecasts = fc.samples,
  in_type = "samples",
  distr = "discrete",
  seed = 42
)
```
The function returns the *reconciled forecast samples*.
```{r res}
reconciled_samples <- recon.res$reconciled_samples
dim(reconciled_samples)

```

With a few last lines of code we calculate the performance on the bottom time series. We compute the Mean Absolute Error (MAE), and the Continuous Ranked Probability Score (CRPS). For the latter, we use `crps_sample` from the package `scoringRules` ([R CRAN](https://cran.r-project.org/package=scoringRules)).

```{r metrics}
# install.packages("scoringRules", dependencies = TRUE)
library(scoringRules)

ae.fc <- list()
ae.reconc <- list()
crps.fc <- list()
crps.reconc <- list()
for (h in 1:length(test)) {
  y.hat_ <- median(fc.samples[[nrow(A) + h]])
  y.reconc_ <- median(recon.res$bottom_reconciled_samples[, h])
  # Compute Absolute Errors
  ae.fc[[h]] <- abs(test[h] - y.hat_)
  ae.reconc[[h]] <- abs(test[h] - y.reconc_)
  # Compute Continuous Ranked Probability Score (CRPS)
  crps.fc[[h]] <-
    scoringRules::crps_sample(y = test[h], dat = fc.samples[[nrow(A) + h]])
  crps.reconc[[h]] <-
    scoringRules::crps_sample(y = test[h], dat = recon.res$bottom_reconciled_samples[, h])
}

mae.fc <- mean(unlist(ae.fc))
mae.reconc <- mean(unlist(ae.reconc))
crps.fc <- mean(unlist(crps.fc))
crps.reconc <- mean(unlist(crps.reconc))
metrics <- data.frame(
  row.names = c("MAE", "CRPS"),
  base.forecasts = c(mae.fc, crps.fc),
  reconciled.forecasts = c(mae.reconc, crps.reconc)
)
metrics

```

# Example 2: M3

In this example, we consider a *monthly* time series (N1402) from the M3 forecasting competition [@makridakis2000m3].

You can obtain it via `bayesRecon::M3sample`.

```{r m3-plot, dpi=300, out.width = "100%", fig.align='center', fig.cap="**Figure 3**: M3: N1402 time series.", fig.dim = c(6, 3)}
plot(M3example$train, xlab = "Time", ylab = "y", main = "N1402")
```
<br>
We build the temporal hierarchy using the `temporal_aggregation` function. We aggregate at *2-Monthly*, *Quarterly*, *4-Monthly*, *Biannual*, *Annual*. We do not specify the `agg_levels` argument since it is automatically  generated by the function by taking all the factors of the time series frequency (i.e. `frequency(M3example$train)`).

```{r m3-agg} 
train.agg <- bayesRecon::temporal_aggregation(M3example$train)
levels <- c("Annual", "Biannual", "4-Monthly", "Quarterly", "2-Monthly", "Monthly")
names(train.agg) <- levels
```

We need to forecast the next 18 month. 
We use the ets forecasting models from the package `forecast` ([R CRAN](https://cran.r-project.org/package=forecast)) to generate gaussian predictions for each temporal level, for each *h*. The forecasting horizon is determined for each temporal level.

```{r m3-fore}
# install.packages("forecast", dependencies = TRUE)
library(forecast)

H <- length(M3example$test)
H

fc <- list()
level.idx <- 1
fc.idx <- 1
for (level in train.agg) {
  level.name <- names(train.agg)[level.idx]
  # fit an ETS model for each temporal level
  model <- ets(level)
  # generate forecasts for each level within 18 months
  h <- floor(H / (12 / frequency(level)))
  print(paste("Forecasting at ", level.name, ", h=", h, "...", sep = ""))
  level.fc <- forecast(model, h = h)
  # save mean and sd of the gaussian predictive distribution
  for (i in 1:h) {
    fc[[fc.idx]] <- c(level.fc$mean[[i]],
                      (level.fc$upper[, "95%"][[i]] - level.fc$mean[[i]]) / qnorm(0.975))
    fc.idx <- fc.idx + 1
  }
  level.idx <- level.idx + 1
}
```

Use Gaussian reconciliation, to ensure *coherent* forecasts. 

We obtain the summing matrix $\mathbf{S}$ using the function `get_reconc_matrices`.

```{r m3-rmat, dpi=300, out.width = "50%", fig.align='center', fig.cap="**Figure 4**: M3: A reconciliation matrix.", fig.dim = c(6, 6)}
rmat <- get_reconc_matrices(agg_levels = c(2, 3, 4, 6, 12), h = 18)

par(mai = c(0,0,0,0))
image(t(apply(t(rmat$A),1,rev)), xaxt='n', yaxt='n', ann=FALSE)
```
<br>
We use the function `reconc_gaussian` which implements the closed-form Gaussian reconciliation,
and the function `reconc_BUIS` which implements the Bottom-Up Important Sampling (BUIS) algorithm. The two results are equivalent the more we increase the number of samples.

```{r m3-reco} 
recon.gauss <- bayesRecon::reconc_gaussian(
  S = rmat$S,
  base_forecasts.mu = sapply(fc, "[[", 1),
  base_forecasts.Sigma = diag(sapply(fc, "[[", 2)) ^ 2
)

reconc.buis <- bayesRecon::reconc_BUIS(
  S = rmat$S,
  base_forecasts = fc,
  in_type = "params",
  distr = "gaussian",
  num_samples = 20000,
  seed = 42
)

round(rbind(
  c(recon.gauss$upper_reconciled_mean, recon.gauss$bottom_reconciled_mean),
  rowMeans(reconc.buis$reconciled_samples)
))
```

Visualize the *reconciled forecasts*.

```{r m3-plotfore, dpi=300, out.width = "100%", fig.align='center', fig.cap="**Figure 5**: M3: visualization of the reconciled forecasts. The red line is the test data, the blu line the recociled mean, the shadow blue region the reconciled 95% confidence interval.", fig.dim = c(6, 4)}
yreconc.mu <- rowMeans(reconc.buis$bottom_reconciled_samples)
yreconc.hi95 <- apply(reconc.buis$bottom_reconciled_samples, 1, function(x) quantile(x, 0.975))
yreconc.lo95 <- apply(reconc.buis$bottom_reconciled_samples, 1, function(x) quantile(x, 0.025))

plot(M3example$train, xlim = c(1990, 1995.6), ylab = "y", main = "N1402 Forecasts")
lines(M3example$test, col = "red")
lines(ts(yreconc.mu, start = start(M3example$test), frequency = 12), col = "blue", lwd = 2)
xtest <- time(M3example$test)
polygon(c(xtest, rev(xtest)), c(yreconc.mu, rev(yreconc.hi95)), col = "#0000FF4C", border = "#0000FF4C")
polygon(c(xtest, rev(xtest)), c(yreconc.mu, rev(yreconc.lo95)), col = "#0000FF4C", border = "#0000FF4C")
```

# Example 3: Infants mortality

In this example, we consider the *infantgts* time series dataset [@hyndman2011optimal].

You can obtain it via `bayesRecon::infantMortality`.

It is a *yearly* grouped **cross-sectional** time series dataset, from 1901 to 2003, of infant mortality counts (deaths) in Australia; disaggregated by state, and sex (male and female). \
States code refer to: New South Wales (NSW), Victoria (VIC), Queensland (QLD), South Australia (SA), Western Australia (WA), Northern Territory (NT), Australian Capital Territory (ACT), and Tasmania (TAS).

We want to forecast the next year (2004). We use the auto.arima forecasting models from the package `forecast` ([R CRAN](https://cran.r-project.org/package=forecast)) to generate gaussian predictions for each node of the hierarchy. 

For each model we collect the residuals.

```{r infants-forecasts}
# install.packages("forecast", dependencies = TRUE)
library(forecast)

fc <- list()
residuals <- matrix(NA,
                    nrow = length(infantMortality$total),
                    ncol = length(infantMortality))
fc.idx <- 1
for (s in infantMortality) {
  s.name <- names(infantMortality)[fc.idx]
  print(paste("Forecasting at ", s.name, "...", sep = ""))
  # fit an auto.arima model and forecast with h=1
  model <- auto.arima(s)
  s.fc <- forecast(model, h = 1)
  # save mean and sd of the gaussian predictive distribution
  fc[[s.name]] <- c(s.fc$mean,
                    (s.fc$upper[, "95%"][[1]] - s.fc$mean) / qnorm(0.975))
  residuals[, fc.idx] <- s.fc$residuals
  fc.idx <- fc.idx + 1
}
```

Build the $\mathbf{S}$ matrix.

```{r infants-s}
# we have 16 bottom time series, and 11 upper time series
A <- matrix(data = c(1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,
                     1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
                     0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,
                     0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,
                     0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,
                     0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,
                     0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,
                     0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,
                     0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,
                     1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,
                     0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1), byrow=TRUE, ncol = 16)
S <- rbind(A, diag(16))
```

Use Gaussian reconciliation, to ensure *coherent* forecasts. 

We use a shrinkage estimation of the covariance matrix of the residuals.

```{r infants reconc}
# Shrinkage estimation of a Covariance Matrix function (@hts:::shrink.estim)
shrink.covariance <- function (x, tar) {
  p <- ncol(x)
  n <- nrow(x)
  covm <- crossprod(x) / n
  corm <- cov2cor(covm)
  xs <- scale(x, center = FALSE, scale = sqrt(diag(covm)))
  v <- (1 / (n * (n - 1))) * (crossprod(xs ^ 2) - 1 / n * (crossprod(xs)) ^ 2)
  diag(v) <- 0
  corapn <- cov2cor(tar)
  d <- (corm - corapn) ^ 2
  lambda <- sum(v) / sum(d)
  lambda <- max(min(lambda, 1), 0)
  shrink.cov <- lambda * tar + (1 - lambda) * covm
  return(list(cov.shrink = shrink.cov, lambda = lambda))
}

# means
mu <- sapply(fc, "[[", 1)
# Sample covariance
Sigma.sample <- cov(residuals)
# Shrinkage covariance
Sigma <- shrink.covariance(residuals, tar = diag(diag(Sigma.sample)))$cov.shrink
```

The function `reconc_gaussian` implements the closed-form Gaussian reconciliation. It requires the covariance matrix, and the vector of means.

```{r infants-recon}
recon.gauss <- bayesRecon::reconc_gaussian(S,
                                           base_forecasts.mu = mu,
                                           base_forecasts.Sigma = Sigma)

# point forecasts
pf <- c(recon.gauss$upper_reconciled_mean,
        recon.gauss$bottom_reconciled_mean)
round(pf, 2)
```

# References
<div id="refs"></div>
