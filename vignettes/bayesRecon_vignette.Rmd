---
title: "Probabilistic Reconciliation via Conditioning with `bayesRecon`"
author: "Nicolò Rubattu, Giorgio Corani, Dario Azzimonti, Lorenzo Zambon"
date: "2023-06-28"
lang: "en"
output: html_vignette
bibliography: references.bib
cite:
- '@zambon2022probabilistic'
- '@zambon2023properties'
- '@corani2023probabilistic'
- '@corani2021probabilistic'
- '@athanasopoulos2017forecasting'
- '@wickramasuriya2019optimal'
vignette: >
  %\VignetteIndexEntry{Probabilistic Reconciliation via Conditioning with `bayesRecon`}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval=TRUE ### !!!! set to FALSE here to render only the text !!!!
)
set.seed(42)
```

```{r klippy, echo=FALSE, include=TRUE, eval=FALSE}
klippy::klippy(position = c('top', 'right'), tooltip_message = 'Copy', tooltip_success = 'Done', color="black")
```

# Introduction

This vignette demostrates how to use the `bayesRecon` package to *reconcile hierarchical probabilistic forecasts*.

The **Carpart** example uses temporal hierarchy and the Bottom-Up Importance Sampling (BUIS) reconciliation algorithm for count time series.

The **M3** example... [temporal gaussian] TODO

The **Infants mortality** example... [cross-sectional gaussian] TODO

For the theory behind the implemented reconciliation algorithms, we encorage readers to refer to the following papers:

* Zambon, L., Azzimonti, D., & Corani, G. (2022). Probabilistic reconciliation of forecasts via importance sampling. *arXiv preprint arXiv:2210.02286*.

* Zambon, L., Agosto, A., Giudici, P., & Corani, G. (2023). Properties of the reconciled distributions for Gaussian and count forecasts. *arXiv preprint arXiv:2303.15135*.

* Corani, G., Azzimonti, D., & Rubattu, N. (2023). Probabilistic reconciliation of count time series. *International Journal of Forecasting*.

* Corani, G., Azzimonti, D., Augusto, J. P., & Zaffalon, M. (2021). Probabilistic reconciliation of hierarchical forecast via Bayes’ rule. In *Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2020, Ghent, Belgium, September 14–18, 2020, Proceedings, Part III* (pp. 211-226).

Also: 

* Athanasopoulos, G., Hyndman, R. J., Kourentzes, N., & Petropoulos, F. (2017). Forecasting with temporal hierarchies. *European Journal of Operational Research*, 262(1), 60-74.

* Wickramasuriya, S. L., Athanasopoulos, G., & Hyndman, R. J. (2019). Optimal forecast reconciliation for hierarchical and grouped time series through trace minimization. *Journal of the American Statistical Association*, 114(526), 804-819.

# Setup

You can install the stable version of `bayesRecon` on [R CRAN](https://cran.r-project.org/package=bayesRecon).

```{r install, eval=FALSE}
install.packages('bayesRecon', dependencies = TRUE)
```

Load the package.
```{r load}
library(bayesRecon)
```

# Example 1: Carpart
In this example, we consider a *monthly* time series of car part sales, from Jan. 1998 to Mar. 2002. \
Precisely, it is the #2655 time series of the *carparts* dataset [@hyndman2008forecasting].

The time series consists of **count** data, and the values distribution is peaked at low values. Hence, we will use count type forecasts.

```{r carpart-plot, dpi=300, out.width = "100%", fig.align='center', fig.cap="**Figure 1**: Monthly car part sales.", fig.dim = c(6, 3)}
layout(mat = matrix(c(1, 2), nrow = 1, ncol = 2), widths = c(2, 1))
plot(carpart, xlab = "Time", ylab = "Car part sales", main = NULL)
hist(carpart, xlab = "Car part sales", main = NULL)
```
<br><br>
We use a simple train-test split, and we want to forecast the last 12 observations (i.e. 1 year).
```{r train-test}
train <- window(carpart, end = c(2001, 3))
test <- window(carpart, start = c(2001, 4))
```

In order to do hierarchical forecasting:

1.    we build a temporal hierarchy;
2.    we obtain the predictions (*base forecasts*) at each temporal scale.

We build the hierarchy using the `temporal aggregation` function. We aggregate at *2-Monthly*, *Quarterly*, *4-Monthly*, *Biannual*, *Annual* by specifying the `agg_levels` argument.

``` {r temp-agg}
train.agg <- bayesRecon::temporal_aggregation(train, agg_levels = c(2, 3, 4, 6, 12))
levels <- c("Annual", "Biannual", "4-Monthly", "Quarterly", "2-Monthly", "Monthly")
names(train.agg) <- levels
```

The function returns a list of aggregated time series, ordered from the most aggregated to the bottom level.
``` {r temp-agg-plot, dpi=300, fig.show="hold", out.width="100%", out.heigth="100%", fig.align='center', fig.cap="**Figure 2**: Aggregates time series visualization.", fig.dim=c(6,3.5)}
par(mfrow = c(2, 3), mai = c(0.6, 0.6, 0.5, 0.5))
for (l in levels) {
  plot(train.agg[[l]], xlab = "Time", ylab = "Car part sales", main = l)
}
```
<br><br>
Since our package only implements reconciliation methods, we use a Generalized Linear Autoregressive Moving Average Model for discrete data with Poisson distribution from the package `glarma` ([R CRAN](https://cran.r-project.org/package=glarma)) to generate the predictive distributions.

The models produce forecasts for 1 year ahead, *h* steps ahead according to the temporal level.
For instance, *h=12* for the monthly level, and *h=4* for the quarterly level. 
Forecasts are in the form of samples. Each forecast is constituted by $\mathbf{B}$ samples.

In the code below a for loop is used to iterating over the temporal aggregation levels.
For each of this, an independent model is fitted. We set $\mathbf{B}=20000$.
Future samples are obtained via simulation, see the documentation of `glarma::forecast.glarma` for details.
We collect the samples in a list of length equal to the number of predictive distributions, $28$ in this example (one for *Annual*, two for *Biannual*, etc.).

``` {r hier-fore}
# install.packages("glarma", dependencies = TRUE)
library(glarma)

fc.samples <- list()
B <- 20000
fc.count <- 1
# iterating over the temporal aggregation levels [~ 30 seconds]
for (l in seq_along(train.agg)) {
  f.level <- frequency(train.agg[[l]])
  print(paste("Forecasting at ", levels[l], "...", sep = ""))
  # fit an independent model for each aggregation level
  model <- glarma::glarma(
    train.agg[[l]],
    phiLags = if (f.level == 1) 1 else 1:(min(6, f.level - 1)),
    thetaLags = if (f.level == 1) NULL else f.level,
    X = cbind(intercept = rep(1, length(train.agg[[l]]))),
    offset = cbind(intercept = rep(0, length(train.agg[[l]]))),
    type = "Poi"
  )
  # forecast 1 year ahead
  h <- f.level
  tmp <- matrix(data = NA, nrow = h, ncol = B)
  for (s in (1:B)) {
    # each call to 'forecast.glarma' returns a simulation path
    tmp[, s] <- forecast(
      model,
      n.ahead = h,
      newdata = cbind(intercept = rep(1, h)),
      newoffset = rep(0, h)
    )$Y
  }
  # collect the forecasted samples
  for (i in 1:h) {
    fc.samples[[fc.count]] <- tmp[i, ]
    fc.count <- fc.count + 1
  }
}

```

It is now the reconciliation turn, to ensure *coherent* forecasts.

We obtain the summing matrix $\mathbf{S}$ using the function `get_reconc_matrices`. It requires the aggregation factors (the same that were used before to build the hierarchy), and the forecasting horizon for the bottom time series (*h=12* in this example).

``` {r S}
recon.matrices <- bayesRecon::get_reconc_matrices(agg_levels = c(2, 3, 4, 6, 12),
                                                  h = 12)
S <- recon.matrices$S # Summing matrix
A <- recon.matrices$A # A matrix
```

We use the function `reconc_BUIS` which implements the Bottom-Up Important Sampling (BUIS) algorithm.
It requires the $\mathbf{S}$ matrix, the *base forecasts*, the specification of the input type of the base forecasts ("samples" in this example), and the specification of the base forecasts distributions ("discrete" in this example, since the predictive distributions are Poisson).

``` {r reconc}
recon.res <- bayesRecon::reconc_BUIS(
  S,
  base_forecasts = fc.samples,
  in_type = "samples",
  distr = "discrete",
  seed = 42
)
```
The function returns the *reconciled forecast samples*.
```{r res}
reconciled_samples <- recon.res$reconciled_samples
dim(reconciled_samples)

```

With a few last lines of code we calculate the performance on the bottom time series. We compute the Mean Absolute Error (MAE), and the Continuous Ranked Probability Score (CRPS). For the latter, we use `crps_sample` from the package `scoringRules` ([R CRAN](https://cran.r-project.org/package=scoringRules)).

```{r metrics}
# install.packages("scoringRules", dependencies = TRUE)

library(scoringRules)

ae.fc <- list()
ae.reconc <- list()
crps.fc <- list()
crps.reconc <- list()
for (h in 1:length(test)) {
  y.hat_ <- median(fc.samples[[nrow(A) + h]])
  y.reconc_ <- median(recon.res$bottom_reconciled_samples[, h])
  # Compute Absolute Errors
  ae.fc[[h]] <- abs(test[h] - y.hat_)
  ae.reconc[[h]] <- abs(test[h] - y.reconc_)
  # Compute Continuous Ranked Probability Score (CRPS)
  crps.fc[[h]] <-
    scoringRules::crps_sample(y = test[h], dat = fc.samples[[nrow(A) + h]])
  crps.reconc[[h]] <-
    scoringRules::crps_sample(y = test[h], dat = recon.res$bottom_reconciled_samples[, h])
}

mae.fc <- mean(unlist(ae.fc))
mae.reconc <- mean(unlist(ae.reconc))
crps.fc <- mean(unlist(crps.fc))
crps.reconc <- mean(unlist(crps.reconc))
metrics <- data.frame(
  row.names = c("MAE", "CRPS"),
  base.forecasts = c(mae.fc, crps.fc),
  reconciled.forecasts = c(mae.reconc, crps.reconc)
)
metrics

```

# Example 2: M3

TODO

# Example 3: Infants mortality

TODO

# References
<div id="refs"></div>
